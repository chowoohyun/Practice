{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQxvI2LwqkCk"
      },
      "outputs": [],
      "source": [
        "#SRGAN(Super Resolution GAN)\n",
        "\n",
        "# /content/drive/MyDrive/data/GAN/img_align_celeba\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import torchvision.transforms as tf\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from PIL import Image\n",
        "import torch"
      ],
      "metadata": {
        "id": "VUK3d4M1q5B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CelebA(Dataset):\n",
        "    def __init__(self):\n",
        "        self.imgs = glob.glob('/content/drive/MyDrive/data/GAN/img_align_celeba/*.jpg')\n",
        "\n",
        "        #해상도 낮은 이미지\n",
        "        self.low_res_tf = tf.Compose([\n",
        "            tf.Resize((32,32)),\n",
        "            tf.ToTensor(),\n",
        "            tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "        #원본 이미지\n",
        "        self.high_res_tf = tf.Compose([\n",
        "            tf.Resize((64,64)),\n",
        "            tf.ToTensor(),\n",
        "            tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        img = Image.open(self.imgs[i])\n",
        "\n",
        "        img_low_res = self.low_res_tf(img)\n",
        "        img_high_res = self.high_res_tf(img)\n",
        "\n",
        "        return [img_low_res, img_high_res]\n",
        "\n"
      ],
      "metadata": {
        "id": "OxEERon4rJo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import PReLU\n",
        "from torch.nn.modules import BatchNorm2d\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.PReLU(),# 0이하의 값에서는 기울기를\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x_ = x\n",
        "        x = self.layers(x)\n",
        "\n",
        "        #합성곱 층을거친 후에 원래의 입력 텐서와 더해준다.\n",
        "        x = x_ + x\n",
        "        return x\n",
        "    \n"
      ],
      "metadata": {
        "id": "aYj7cst4rKAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSample(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpSample, self).__init__(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.PixelShuffle(upscale_factor=2),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "    #생성자\n"
      ],
      "metadata": {
        "id": "FeWZaY77wY2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.res_block = nn.Sequential(\n",
        "            ResidualBlock(64,64),\n",
        "            ResidualBlock(64,64),\n",
        "            ResidualBlock(64,64)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64,64,kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.upsample_blocks = nn.Sequential(\n",
        "            UpSample(64,256)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64,3,kernel_size=9, stride=1, padding=4)\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1\n",
        "\n",
        "        #나중에 가서 사용하므로 저장해둠\n",
        "        x_ = x\n",
        "\n",
        "        x = self.res_block(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        x = x + x_\n",
        "\n",
        "        x = self.upsample_blocks(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "WQ88xJD90r_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#판별자의 기본블록\n",
        "\n",
        "class DisBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DisBlock, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "b2Qfvs3z2q2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 감별자 블록\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.blocks = DisBlock(64,64)\n",
        "        self.fc1 = nn.Linear(65536, 1024)\n",
        "        self.activation = nn.LeakyReLU()\n",
        "        self.fc2 = nn.Linear(1024, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.blocks(x)\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_7gGnhOx3xX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특징 추출에는 vgg19를 사용\n",
        "\n",
        "from torchvision.models.vgg import vgg19\n",
        "\n",
        "class FeatureExtactor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtactor, self).__init__()\n",
        "\n",
        "        vgg19_model = vgg19(pretrained=True)\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            *list(vgg19_model.features.children())[:9]\n",
        "        )\n",
        "    \n",
        "    def forward(self, img):\n",
        "        return self.feature_extractor(img)"
      ],
      "metadata": {
        "id": "s7ElfmZn6hYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.adam import Adam"
      ],
      "metadata": {
        "id": "hMiAbv1C8s4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "s5aJFzjK8uO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CelebA()\n",
        "batch_size = 8\n",
        "loader = DataLoader(dataset, batch_size= batch_size, shuffle=True)\n",
        "\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "feature_extractor = FeatureExtactor().to(device)\n",
        "feature_extractor.eval()\n",
        "\n",
        "G_optim = Adam(G.parameters(), lr = 0.0001, betas =(0.5, 0.999))\n",
        "D_optim = Adam(D.parameters(), lr = 0.0001, betas =(0.5, 0.999))\n"
      ],
      "metadata": {
        "id": "45GTGoi48uMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XkZESzm7-Pml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}