{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaUZXJsnnlx7"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ml4py/dataset-iiit-pet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "annotation = Image.open('./dataset-iiit-pet/annotations/trimaps/Abyssinian_1.png')\n",
        "plt.imshow(annotation)"
      ],
      "metadata": {
        "id": "1GEDjc8go2ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open('./dataset-iiit-pet/images/Abyssinian_1.jpg')\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "BALJljAep2aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "\n",
        "images = sorted(glob.glob('./dataset-iiit-pet/images/*.jpg'))\n",
        "\n",
        "for temp in images:\n",
        "    result = cv2.imread(temp, cv2.IMREAD_COLOR)\n",
        "    cv2.imwrite(temp,result)"
      ],
      "metadata": {
        "id": "ORqCh3_xqLq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "id": "wAGR5PIjq5XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "uhVaA9uXrTla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pet(Dataset):\n",
        "    def __init__(self,path_to_img,path_to_anno,train=True,transforms=None,input_size=(128,128)):\n",
        "        #정답과 입력 이미지를 이름순으로 정렬\n",
        "\n",
        "        self.images = sorted(glob.glob('./dataset-iiit-pet/images/*.jpg'))\n",
        "        self.annotations = sorted(glob.glob('./dataset-iiit-pet/annotations/trimaps/*.png'))\n",
        "\n",
        "        #데이터셋을 학습(80%) 평가용(20%)로 나눔\n",
        "        self.X_train = self.images[:int(0.8 * len(self.images))]\n",
        "        self.X_test = self.images[int(0.8 * len(self.images)):]\n",
        "        self.Y_train = self.annotations[:int(0.8 * len(self.annotations))]\n",
        "        self.Y_test = self.annotations[int(0.8 * len(self.annotations)):]\n",
        "\n",
        "        self.train = train\n",
        "        self.transforms = transforms\n",
        "        self.input_size = input_size\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return len(self.X_train)\n",
        "        else :\n",
        "            return len(self.X_test)\n",
        "\n",
        "    def preprocess_mask(self,mask):\n",
        "        mask = mask.resize(self.input_size)\n",
        "        mask = np.array(mask).astype(np.float32)\n",
        "        mask[mask != 2.0 ] = 1.0\n",
        "        mask[mask == 2.0 ] = 0.0\n",
        "        mask = torch.tensor(mask)\n",
        "        return mask\n",
        "\n",
        "    def __getitem__(self,i):  #i번째 데이터와 정답을 리턴\n",
        "        if self.train:\n",
        "            X_train = Image.open(self.X_train[i])\n",
        "            X_train = self.transforms(X_train)\n",
        "            Y_train = Image.open(self.Y_train[i])\n",
        "            Y_train = self.preprocess_mask(Y_train)\n",
        "\n",
        "            return X_train, Y_train\n",
        "        else:\n",
        "            X_test = Image.open(self.X_test[i])\n",
        "            X_test = self.transforms(X_test)\n",
        "            Y_test = Image.open(self.Y_test[i])\n",
        "            Y_test = self.preprocess_mask(Y_test)  \n",
        "\n",
        "            return X_test, Y_test\n",
        "        "
      ],
      "metadata": {
        "id": "lkDAd3hzrhQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet,self).__init__()\n",
        "\n",
        "        #Unet encoder\n",
        "\n",
        "        self.enc1_1 = nn.Conv2d(3,64,kernel_size=3,padding=1)\n",
        "        self.enc1_2 = nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "        self.enc2_1 = nn.Conv2d(64,128,kernel_size=3,padding=1)\n",
        "        self.enc2_2 = nn.Conv2d(128,128,kernel_size=3,padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "        self.enc3_1 = nn.Conv2d(128,256,kernel_size=3,padding=1)\n",
        "        self.enc3_2 = nn.Conv2d(256,256,kernel_size=3,padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "        self.enc4_1 = nn.Conv2d(256,512,kernel_size=3,padding=1)\n",
        "        self.enc4_2 = nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "        self.enc5_1 = nn.Conv2d(512,1024,kernel_size=3,padding=1)\n",
        "        self.enc5_2 = nn.Conv2d(1024,512,kernel_size=3,padding=1)\n",
        "\n",
        "        #Unet decoder\n",
        "        self.upsample4 = nn.ConvTranspose2d(512,512,2,stride=2)\n",
        "        self.dec4_1 = nn.Conv2d(1024,512,kernel_size=3,padding=1)\n",
        "        self.dec4_2 = nn.Conv2d(512,256,kernel_size=3,padding=1)\n",
        "\n",
        "        self.upsample3 = nn.ConvTranspose2d(256,256,2,stride=2)\n",
        "        self.dec3_1 = nn.Conv2d(512,256,kernel_size=3,padding=1)\n",
        "        self.dec3_2 = nn.Conv2d(256,128,kernel_size=3,padding=1)\n",
        "\n",
        "        self.upsample2 = nn.ConvTranspose2d(128,128,2,stride=2)\n",
        "        self.dec2_1 = nn.Conv2d(256,128,kernel_size=3,padding=1)\n",
        "        self.dec2_2 = nn.Conv2d(128,64,kernel_size=3,padding=1)\n",
        "\n",
        "        self.upsample1 = nn.ConvTranspose2d(64,64,2,stride=2)\n",
        "        self.dec1_1 = nn.Conv2d(128,64,kernel_size=3,padding=1)\n",
        "        self.dec1_2 = nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
        "        self.dec1_3 = nn.Conv2d(64,1,kernel_size=1)\n",
        "\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.enc1_1(x)\n",
        "        x = self.relu(x)\n",
        "        e1 = self.enc1_2(x)\n",
        "        e1 = self.relu(e1)\n",
        "        x = self.pool1(e1)\n",
        "\n",
        "        x = self.enc2_1(x)\n",
        "        x = self.relu(x)\n",
        "        e2 = self.enc2_2(x)\n",
        "        e2 = self.relu(e2)\n",
        "        x = self.pool2(e2)\n",
        "\n",
        "        x = self.enc3_1(x)\n",
        "        x = self.relu(x)\n",
        "        e3 = self.enc3_2(x)\n",
        "        e3 = self.relu(e3)\n",
        "        x = self.pool3(e3)\n",
        "\n",
        "        x = self.enc4_1(x)\n",
        "        x = self.relu(x)\n",
        "        e4 = self.enc4_2(x)\n",
        "        e4 = self.relu(e4)\n",
        "        x = self.pool4(e4)\n",
        "\n",
        "        x = self.enc5_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.enc5_2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.upsample4(x)\n",
        "        x = torch.cat([x,e4],dim=1)\n",
        "        x = self.dec4_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dec4_2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.upsample3(x)\n",
        "        x = torch.cat([x,e3],dim=1)\n",
        "        x = self.dec3_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dec3_2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.upsample2(x)\n",
        "        x = torch.cat([x,e2],dim=1)\n",
        "        x = self.dec2_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dec2_2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.upsample1(x)\n",
        "        x = torch.cat([x,e1],dim=1)\n",
        "        x = self.dec1_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dec1_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dec1_3(x)\n",
        "\n",
        "        x = torch.squeeze(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "bjGo3LBhwbjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "import tqdm\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms import ToTensor,Resize\n",
        "from torch.optim.adam import Adam\n",
        "from torch.utils.data.dataloader import DataLoader"
      ],
      "metadata": {
        "id": "mxhqZV9cN6SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "fa72fKuOOVcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = Compose([\n",
        "    Resize((128,128)),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "train_set = Pet(path_to_img = './dataset-iiit-pet/images',path_to_anno='./dataset-iiit-pet/annotations/trimaps',transforms=transform)\n",
        "test_set = Pet(path_to_img = './dataset-iiit-pet/images',path_to_anno='./dataset-iiit-pet/annotations/trimaps',transforms=transform, train=False)\n",
        "\n",
        "print( len(train_set) )\n",
        "print( len(test_set) )"
      ],
      "metadata": {
        "id": "959Ii_KDOkRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(test_set)\n",
        "\n",
        "model = UNet().to(device)\n",
        "\n",
        "lr = 0.0001\n",
        "\n",
        "optim = Adam(params=model.parameters(),lr=lr)\n"
      ],
      "metadata": {
        "id": "AWaTvr-cPwqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "    iterator = tqdm.tqdm(train_loader)\n",
        "\n",
        "    for data,label in iterator:\n",
        "        optim.zero_grad()\n",
        "        preds = model(data.to(device))\n",
        "        loss = nn.BCEWithLogitsLoss()(\n",
        "            preds,label.type(torch.FloatTensor).to(device))\n",
        "\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        iterator.set_description(f'epoch{epoch+1} loss{loss.item()}')\n",
        "\n",
        "    torch.save(model.state_dict() , '/content/drive/MyDrive/unet.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "HJiBaBVuQWNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#추론코드 - cpu\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = UNet()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/unet_final.pth'))\n",
        "\n",
        "data,label = test_set[1]\n",
        "print(data.shape)\n",
        "pred = model(torch.unsqueeze(data.to('cpu'), dim=0)) > 0.5\n",
        "print(pred.shape)\n",
        "\n",
        "with torch.no_grad():\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('Predicted')\n",
        "    plt.imshow(pred)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('label')\n",
        "    plt.imshow(label)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "I0NqoUBZSBxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#추론코드 - gpu\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model = UNet()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/unet_final.pth' , map_location='cuda'))\n",
        "model.to('cuda')\n",
        "\n",
        "data,label = test_set[1]\n",
        "print(data.shape)\n",
        "pred = model(torch.unsqueeze(data.to('cuda'), dim=0)) > 0.5\n",
        "\n",
        "pred = pred.to('cpu')\n",
        "\n",
        "with torch.no_grad():\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('Predicted')\n",
        "    plt.imshow(pred)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('label')\n",
        "    plt.imshow(label)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XY7hQYmEjwK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SH2C4EaBlM_U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}